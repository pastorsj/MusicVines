#import the necessary packages
import argparse
import datetime
import imutils
import time
import cv2
 
# construct the argument parser and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-v", "--video", help="path to the video file")
ap.add_argument("-a", "--min-area", type=int, default=200, help="minimum area size")
args = vars(ap.parse_args())
 
# if the video argument is None, then we are reading from webcam
if args.get("video", None) is None:
	camera = cv2.VideoCapture(0)
	time.sleep(0.25)
# otherwise, we are reading from a video file
else:
	camera = cv2.VideoCapture(args["video"])
print "cam width:   " + str(camera.get(3))
print "cam height:   " + str(camera.get(4))
# initialize the first frame in the video stream
firstFrame = None
gray = None
# loop over the frames of the video
count = 0
largestBoxFrame = None
largestBoxFrameSmallestX = 10000
largestBoxFrameSmallestY = 10000
largestBoxFrameLargestX = -1
largestBoxFrameLargestY = -1
largestBoxFrameSize = 0
maxSize = 0
while True:
	smallestX = 10000
	largestX = -1
	smallestY = 10000
	largestY = -1
	# grab the current frame and initialize the occupied/unoccupied
	(grabbed, frame) = camera.read()

	# if the frame could not be grabbed, then we have reached the end of the video
	if not grabbed:
		break

	if gray is not None:
		firstFrame = gray
	# resize the frame, convert it to grayscale, and blur it
	#frame = imutils.resize(frame, width=500)
	gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	gray = cv2.GaussianBlur(gray, (21,21), 0)
	maxSize = round(frame.shape[0]*frame.shape[1]*0.25)

	# if the first frame is None, initialize it
	if firstFrame is None:
		firstFrame = gray
		continue

	# compute the absolute difference between the current frame and first frame
	frameDelta = cv2.absdiff(firstFrame, gray)
	thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]

	# dilate the thresholded image to fill in holes, then find contours on thresholded image
	thresh = cv2.dilate(thresh, None, iterations=2)
	(a, cnts, b) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
	
	# loop over the contours
	for c in cnts:
		# if the contour is too small, ignore it
		if cv2.contourArea(c) < args["min_area"]:
			continue

		# compute the bounding box for the contour
		(x, y, w, h) = cv2.boundingRect(c)
		if x < smallestX:
			smallestX = x
		elif x+w > largestX:
			largestX = x+w

		if y < smallestY:
			smallestY = y
		elif y+h > largestY:
			largestY = y+h


	if(smallestX != 10000 and smallestY != 10000 and largestX != -1 and largestY != -1 and maxSize > (largestX-smallestX)*(largestY-smallestY)):
		cv2.rectangle(frame, (smallestX,largestY), (largestX, smallestY), (0,255,0), 2)
		#print str(largestY*largestX)
		boxSize = (largestX-smallestX)*(largestY-smallestY)
		if(boxSize > largestBoxFrameSize):
			largestBoxFrameSmallestX = smallestX
			largestBoxFrameSmallestY = smallestY
			largestBoxFrameLargestX = largestX
			largestBoxFrameLargestY = largestY
			largestBoxFrameSize = boxSize
			largestBoxFrame = frame

	# show the frame and record if the user presses a key
	cv2.imshow("Bounding box", frame)
	key = cv2.waitKey(10) & 0xFF

	if count == 300:
		break
	count = count + 1

blueAvg = 0.0
greenAvg = 0.0
redAvg = 0.0
numPoints = float(largestBoxFrameSize)
for i in range(largestBoxFrameSmallestX, largestBoxFrameLargestX):
	for j in range(largestBoxFrameSmallestY, largestBoxFrameLargestY):
		colors = largestBoxFrame[j, i]
		blueAvg += colors[0]*1000/numPoints
		greenAvg += colors[1]*1000/numPoints
		redAvg += colors[2]*1000/numPoints

blueAvg = blueAvg/1000
greenAvg = greenAvg/1000
redAvg = redAvg/1000

print "blueAvg:   " + str(blueAvg)
print "greenAvg:    " + str(greenAvg)
print "redAvg:     " + str(redAvg)
cv2.imshow("Largest Box Frame", largestBoxFrame)

while True:
	cv2.waitKey(1000)

# cleanup the camera and close any open windows
camera.release()
cv2.destroyAllWindows()